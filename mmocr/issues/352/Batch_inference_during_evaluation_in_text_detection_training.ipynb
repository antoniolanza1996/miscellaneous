{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch_inference_during_evaluation_in_text_detection_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA08SB-5ZAy-"
      },
      "source": [
        "# Related issue: https://github.com/open-mmlab/mmocr/issues/352"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M-x7vPg96DP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccbc0a4-20b9-4b0f-dfad-63abc9b8cf91"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-db46c46c-e2ff-fa50-9e0c-a98e4d2916da)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6nU3U92zTO9"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZmq8E8M-M_X"
      },
      "source": [
        "%%capture\n",
        "# Install torch dependencies: (use cu101 since colab has CUDA 10.1)\n",
        "!pip install -U torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!pip install mmdet==2.11.0\n",
        "\n",
        "# Install mmocr\n",
        "!git clone https://github.com/open-mmlab/mmocr.git\n",
        "%cd mmocr\n",
        "#Install from commit https://github.com/open-mmlab/mmocr/commit/6d97d8286e333dd8aa613a59c467d6ed85d3d6a3 (i.e. with MMOCR v0.2.0)\n",
        "!git checkout 6d97d8286e333dd8aa613a59c467d6ed85d3d6a3 \n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e .\n",
        "\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2as6SCx_f-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a380682f-547a-46d5-b55c-cea2b5932279"
      },
      "source": [
        "!nvcc -V\n",
        "!gcc --version\n",
        "\n",
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "import mmcv\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(mmcv.__version__)\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check mmocr installation\n",
        "import mmocr\n",
        "print(mmocr.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "1.5.0+cu101 True\n",
            "2.11.0\n",
            "1.3.9\n",
            "10.1\n",
            "GCC 7.3\n",
            "0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toPZdt3OGY4R"
      },
      "source": [
        "## Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taGCWA8dUvQ6",
        "outputId": "b9a84c15-17eb-4794-9b3f-c5e3fad5a1ef"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/antoniolanza1996/miscellaneous/d12b519a089cb4b8a177ca8acf0906ea20d0335a/mmocr/issues/352/dbnet_custom_config.py -O configs/textdet/dbnet/dbnet_custom_config.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-21 13:55:40--  https://raw.githubusercontent.com/antoniolanza1996/miscellaneous/d12b519a089cb4b8a177ca8acf0906ea20d0335a/mmocr/issues/352/dbnet_custom_config.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3258 (3.2K) [text/plain]\n",
            "Saving to: ‘configs/textdet/dbnet/dbnet_custom_config.py’\n",
            "\n",
            "configs/textdet/dbn 100%[===================>]   3.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-21 13:55:40 (44.8 MB/s) - ‘configs/textdet/dbnet/dbnet_custom_config.py’ saved [3258/3258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u91tg9AkifXn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff865f69-ce3e-4a28-fa3e-035fff5bdb5d"
      },
      "source": [
        "%%shell\n",
        "\n",
        "WORK_DIR=\"../textdet_output\"\n",
        "mkdir -p $WORK_DIR\n",
        "\n",
        "python3 tools/train.py ./configs/textdet/dbnet/dbnet_custom_config.py \\\n",
        "  --seed 42 \\\n",
        "  --work-dir=$WORK_DIR \\\n",
        "  --cfg-options \\\n",
        "    load_from=\"https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\" \\\n",
        "    log_config.interval=1 \\\n",
        "    checkpoint_config.interval=1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-21 13:55:50,834 - mmocr - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.11 (default, Jul  3 2021, 18:01:19) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla T4\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.5.0+cu101\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.6.0+cu101\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 1.3.9\n",
            "MMCV Compiler: GCC 7.3\n",
            "MMCV CUDA Compiler: 10.1\n",
            "MMOCR: 0.2.0+6d97d82\n",
            "------------------------------------------------------------\n",
            "\n",
            "2021-07-21 13:55:51,483 - mmocr - INFO - Distributed training: False\n",
            "2021-07-21 13:55:52,075 - mmocr - INFO - Config:\n",
            "optimizer = dict(type='SGD', lr=0.007, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(policy='poly', power=0.9, min_lr=1e-07, by_epoch=True)\n",
            "total_epochs = 100\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=1, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = 'https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "model = dict(\n",
            "    type='DBNet',\n",
            "    pretrained='torchvision://resnet50',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=-1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=False,\n",
            "        style='caffe',\n",
            "        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),\n",
            "        stage_with_dcn=(False, True, True, True)),\n",
            "    neck=dict(\n",
            "        type='FPNC', in_channels=[256, 512, 1024, 2048], lateral_channels=256),\n",
            "    bbox_head=dict(\n",
            "        type='DBHead',\n",
            "        text_repr_type='quad',\n",
            "        in_channels=256,\n",
            "        loss=dict(type='DBLoss', alpha=5.0, beta=10.0, bbce_loss=True)),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "img_norm_cfg = dict(\n",
            "    mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "    std=[255, 255, 255],\n",
            "    to_rgb=False)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='LoadTextAnnotations',\n",
            "        with_bbox=True,\n",
            "        with_mask=True,\n",
            "        poly2mask=False),\n",
            "    dict(type='ColorJitter', brightness=0.12549019607843137, saturation=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "        std=[255, 255, 255],\n",
            "        to_rgb=False),\n",
            "    dict(\n",
            "        type='ImgAug',\n",
            "        args=[['Fliplr', 0.5], {\n",
            "            'cls': 'Affine',\n",
            "            'rotate': [-10, 10]\n",
            "        }, ['Resize', [0.5, 3.0]]]),\n",
            "    dict(type='EastRandomCrop', target_size=(640, 640)),\n",
            "    dict(type='DBNetTargets', shrink_ratio=0.4),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='CustomFormatBundle',\n",
            "        keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\n",
            "        visualize=dict(flag=False, boundary_key='gt_shrink')),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(4068, 1024),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', img_scale=(4068, 1024), keep_ratio=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "                std=[255, 255, 255],\n",
            "                to_rgb=False),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "dataset_type = 'IcdarDataset'\n",
            "prefix = 'tests/data/toy_dataset/'\n",
            "train = dict(\n",
            "    type='IcdarDataset',\n",
            "    ann_file='tests/data/toy_dataset/instances_test.json',\n",
            "    img_prefix='tests/data/toy_dataset/imgs',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(\n",
            "            type='LoadTextAnnotations',\n",
            "            with_bbox=True,\n",
            "            with_mask=True,\n",
            "            poly2mask=False),\n",
            "        dict(\n",
            "            type='ColorJitter', brightness=0.12549019607843137,\n",
            "            saturation=0.5),\n",
            "        dict(\n",
            "            type='Normalize',\n",
            "            mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "            std=[255, 255, 255],\n",
            "            to_rgb=False),\n",
            "        dict(\n",
            "            type='ImgAug',\n",
            "            args=[['Fliplr', 0.5], {\n",
            "                'cls': 'Affine',\n",
            "                'rotate': [-10, 10]\n",
            "            }, ['Resize', [0.5, 3.0]]]),\n",
            "        dict(type='EastRandomCrop', target_size=(640, 640)),\n",
            "        dict(type='DBNetTargets', shrink_ratio=0.4),\n",
            "        dict(type='Pad', size_divisor=32),\n",
            "        dict(\n",
            "            type='CustomFormatBundle',\n",
            "            keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\n",
            "            visualize=dict(flag=False, boundary_key='gt_shrink')),\n",
            "        dict(\n",
            "            type='Collect',\n",
            "            keys=[\n",
            "                'img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'\n",
            "            ])\n",
            "    ])\n",
            "test = dict(\n",
            "    type='IcdarDataset',\n",
            "    ann_file='tests/data/toy_dataset/instances_test.json',\n",
            "    img_prefix='tests/data/toy_dataset/imgs',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(\n",
            "            type='MultiScaleFlipAug',\n",
            "            img_scale=(4068, 1024),\n",
            "            flip=False,\n",
            "            transforms=[\n",
            "                dict(type='Resize', img_scale=(4068, 1024), keep_ratio=True),\n",
            "                dict(\n",
            "                    type='Normalize',\n",
            "                    mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "                    std=[255, 255, 255],\n",
            "                    to_rgb=False),\n",
            "                dict(type='Pad', size_divisor=32),\n",
            "                dict(type='ImageToTensor', keys=['img']),\n",
            "                dict(type='Collect', keys=['img'])\n",
            "            ])\n",
            "    ])\n",
            "data = dict(\n",
            "    samples_per_gpu=4,\n",
            "    workers_per_gpu=4,\n",
            "    val_dataloader=dict(samples_per_gpu=4),\n",
            "    test_dataloader=dict(samples_per_gpu=4),\n",
            "    train=dict(\n",
            "        type='IcdarDataset',\n",
            "        ann_file='tests/data/toy_dataset/instances_test.json',\n",
            "        img_prefix='tests/data/toy_dataset/imgs',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='LoadTextAnnotations',\n",
            "                with_bbox=True,\n",
            "                with_mask=True,\n",
            "                poly2mask=False),\n",
            "            dict(\n",
            "                type='ColorJitter',\n",
            "                brightness=0.12549019607843137,\n",
            "                saturation=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "                std=[255, 255, 255],\n",
            "                to_rgb=False),\n",
            "            dict(\n",
            "                type='ImgAug',\n",
            "                args=[['Fliplr', 0.5], {\n",
            "                    'cls': 'Affine',\n",
            "                    'rotate': [-10, 10]\n",
            "                }, ['Resize', [0.5, 3.0]]]),\n",
            "            dict(type='EastRandomCrop', target_size=(640, 640)),\n",
            "            dict(type='DBNetTargets', shrink_ratio=0.4),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='CustomFormatBundle',\n",
            "                keys=['gt_shrink', 'gt_shrink_mask', 'gt_thr', 'gt_thr_mask'],\n",
            "                visualize=dict(flag=False, boundary_key='gt_shrink')),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=[\n",
            "                    'img', 'gt_shrink', 'gt_shrink_mask', 'gt_thr',\n",
            "                    'gt_thr_mask'\n",
            "                ])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='IcdarDataset',\n",
            "        ann_file='tests/data/toy_dataset/instances_test.json',\n",
            "        img_prefix='tests/data/toy_dataset/imgs',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(4068, 1024),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize', img_scale=(4068, 1024),\n",
            "                        keep_ratio=True),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "                        std=[255, 255, 255],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='IcdarDataset',\n",
            "        ann_file='tests/data/toy_dataset/instances_test.json',\n",
            "        img_prefix='tests/data/toy_dataset/imgs',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(4068, 1024),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize', img_scale=(4068, 1024),\n",
            "                        keep_ratio=True),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[122.67891434, 116.66876762, 104.00698793],\n",
            "                        std=[255, 255, 255],\n",
            "                        to_rgb=False),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='hmean-iou')\n",
            "work_dir = '../textdet_output'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2021-07-21 13:55:52,076 - mmocr - INFO - Set random seed to 42, deterministic: False\n",
            "2021-07-21 13:55:52,441 - mmdet - INFO - load model from: torchvision://resnet50\n",
            "2021-07-21 13:55:52,442 - mmdet - INFO - Use load_from_torchvision loader\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 179MB/s]\n",
            "2021-07-21 13:55:53,474 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.conv_offset.weight, layer2.0.conv2.conv_offset.bias, layer2.1.conv2.conv_offset.weight, layer2.1.conv2.conv_offset.bias, layer2.2.conv2.conv_offset.weight, layer2.2.conv2.conv_offset.bias, layer2.3.conv2.conv_offset.weight, layer2.3.conv2.conv_offset.bias, layer3.0.conv2.conv_offset.weight, layer3.0.conv2.conv_offset.bias, layer3.1.conv2.conv_offset.weight, layer3.1.conv2.conv_offset.bias, layer3.2.conv2.conv_offset.weight, layer3.2.conv2.conv_offset.bias, layer3.3.conv2.conv_offset.weight, layer3.3.conv2.conv_offset.bias, layer3.4.conv2.conv_offset.weight, layer3.4.conv2.conv_offset.bias, layer3.5.conv2.conv_offset.weight, layer3.5.conv2.conv_offset.bias, layer4.0.conv2.conv_offset.weight, layer4.0.conv2.conv_offset.bias, layer4.1.conv2.conv_offset.weight, layer4.1.conv2.conv_offset.bias, layer4.2.conv2.conv_offset.weight, layer4.2.conv2.conv_offset.bias\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/content/mmocr/mmocr/apis/train.py:79: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
            "  'please set `runner` in your config.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/mmdet/datasets/utils.py:68: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
            "  'data pipeline in your config file.', UserWarning)\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "2021-07-21 13:55:56,172 - mmocr - INFO - load checkpoint from https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\n",
            "2021-07-21 13:55:56,173 - mmocr - INFO - Use load_from_http loader\n",
            "Downloading: \"https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\" to /root/.cache/torch/checkpoints/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\n",
            "100% 101M/101M [00:09<00:00, 11.4MB/s] \n",
            "2021-07-21 13:56:06,269 - mmocr - INFO - Start running, host: root@7ec6093f795a, work_dir: /content/textdet_output\n",
            "2021-07-21 13:56:06,270 - mmocr - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(NORMAL      ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(NORMAL      ) EvalHook                           \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(NORMAL      ) EvalHook                           \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(NORMAL      ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2021-07-21 13:56:06,270 - mmocr - INFO - workflow: [('train', 1)], max: 100 epochs\n",
            "2021-07-21 13:56:10,876 - mmocr - INFO - Epoch [1][1/3]\tlr: 7.000e-03, eta: 0:21:57, time: 4.406, data_time: 3.936, memory: 3649, loss_prob: 0.3671, loss_db: 0.0588, loss_thr: 0.2113, loss: 0.6372\n",
            "2021-07-21 13:56:11,470 - mmocr - INFO - Epoch [1][2/3]\tlr: 7.000e-03, eta: 0:12:41, time: 0.703, data_time: 0.203, memory: 3860, loss_prob: 0.2852, loss_db: 0.0570, loss_thr: 0.2546, loss: 0.5968\n",
            "2021-07-21 13:56:12,067 - mmocr - INFO - Exp name: dbnet_custom_config.py\n",
            "2021-07-21 13:56:12,067 - mmocr - INFO - Epoch [1][3/3]\tlr: 7.000e-03, eta: 0:09:24, time: 0.599, data_time: 0.094, memory: 3860, loss_prob: 0.5815, loss_db: 0.1009, loss_thr: 0.2472, loss: 0.9295\n",
            "2021-07-21 13:56:12,161 - mmocr - INFO - Saving checkpoint at 1 epochs\n",
            "[                                                  ] 0/10, elapsed: 0s, ETA:Traceback (most recent call last):\n",
            "  File \"tools/train.py\", line 219, in <module>\n",
            "    main()\n",
            "  File \"tools/train.py\", line 215, in main\n",
            "    meta=meta)\n",
            "  File \"/content/mmocr/mmocr/apis/train.py\", line 161, in train_detector\n",
            "    runner.run(data_loaders, cfg.workflow)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\n",
            "    epoch_runner(data_loaders[i], **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/epoch_based_runner.py\", line 54, in train\n",
            "    self.call_hook('after_train_epoch')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/base_runner.py\", line 307, in call_hook\n",
            "    getattr(hook, fn_name)(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/core/evaluation/eval_hooks.py\", line 146, in after_train_epoch\n",
            "    results = single_gpu_test(runner.model, self.dataloader, show=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/apis/test.py\", line 27, in single_gpu_test\n",
            "    result = model(return_loss=False, rescale=True, **data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/parallel/data_parallel.py\", line 42, in forward\n",
            "    return super().forward(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 153, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmcv/runner/fp16_utils.py\", line 98, in new_func\n",
            "    return old_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/models/detectors/base.py\", line 183, in forward\n",
            "    return self.forward_test(img, img_metas, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/models/detectors/base.py\", line 160, in forward_test\n",
            "    return self.simple_test(imgs[0], img_metas[0], **kwargs)\n",
            "  File \"/content/mmocr/mmocr/models/textdet/detectors/single_stage_text_detector.py\", line 53, in simple_test\n",
            "    for i in range(len(img_metas))\n",
            "  File \"/content/mmocr/mmocr/models/textdet/detectors/single_stage_text_detector.py\", line 53, in <listcomp>\n",
            "    for i in range(len(img_metas))\n",
            "  File \"/content/mmocr/mmocr/models/textdet/dense_heads/head_mixin.py\", line 56, in get_boundary\n",
            "    text_repr_type=self.text_repr_type)\n",
            "  File \"/content/mmocr/mmocr/models/textdet/postprocess/wrapper.py\", line 30, in decode\n",
            "    return db_decode(**kwargs)\n",
            "  File \"/content/mmocr/mmocr/models/textdet/postprocess/wrapper.py\", line 208, in db_decode\n",
            "    cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
            "cv2.error: OpenCV(4.1.2) /io/opencv/modules/core/src/copy.cpp:1170: error: (-215:Assertion failed) top >= 0 && bottom >= 0 && left >= 0 && right >= 0 && _src.dims() <= 2 in function 'copyMakeBorder'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-156bf010cba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nWORK_DIR=\"../textdet_output\"\\nmkdir -p $WORK_DIR\\n\\npython3 tools/train.py ./configs/textdet/dbnet/dbnet_custom_config.py \\\\\\n  --seed 42 \\\\\\n  --work-dir=$WORK_DIR \\\\\\n  --cfg-options \\\\\\n    load_from=\"https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\" \\\\\\n    log_config.interval=1 \\\\\\n    checkpoint_config.interval=1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\nWORK_DIR=\"../textdet_output\"\nmkdir -p $WORK_DIR\n\npython3 tools/train.py ./configs/textdet/dbnet/dbnet_custom_config.py \\\n  --seed 42 \\\n  --work-dir=$WORK_DIR \\\n  --cfg-options \\\n    load_from=\"https://download.openmmlab.com/mmocr/textdet/dbnet/dbnet_r50dcnv2_fpnc_sbn_1200e_icdar2015_20210325-91cef9af.pth\" \\\n    log_config.interval=1 \\\n    checkpoint_config.interval=1' returned non-zero exit status 1."
          ]
        }
      ]
    }
  ]
}